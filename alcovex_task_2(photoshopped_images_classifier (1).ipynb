{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "rPoz22rXcLrs"
      },
      "outputs": [],
      "source": [
        "#importing the libraries\n",
        "import os \n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5us07Z7AcMHl",
        "outputId": "bf4dc398-094a-4613-ec24-f7e6cde9661d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Set the path of the directory containing the images\n",
        "dir_path = '/content/drive/MyDrive/directory_1'\n",
        "\n",
        "# Set the paths of the two new directories for edited and unedited images\n",
        "edited_dir_path = os.path.join(dir_path, '/content/drive/MyDrive/directory_1/edit_1')\n",
        "unedited_dir_path = os.path.join(dir_path, '/content/drive/MyDrive/directory_1/IMAGICA_new')\n",
        "\n",
        "# Create the new directories if they don't already exist\n",
        "if not os.path.exists(edited_dir_path):\n",
        "    os.makedirs(edited_dir_path)\n",
        "if not os.path.exists(unedited_dir_path):\n",
        "    os.makedirs(unedited_dir_path)\n",
        "\n",
        "# Iterate over all files in the original directory\n",
        "for filename in os.listdir(dir_path):\n",
        "    # Check if the file is a JPG image\n",
        "    if filename.endswith('.jpg'):\n",
        "        # Check the last character of the file name to determine if it is edited or unedited\n",
        "        if filename[-1] == '0':\n",
        "            # Move the file to the unedited directory\n",
        "            shutil.move(os.path.join(dir_path, filename), os.path.join(unedited_dir_path, filename))\n",
        "        elif filename[-1] == '1':\n",
        "            # Move the file to the edited directory\n",
        "            shutil.move(os.path.join(dir_path, filename), os.path.join(edited_dir_path, filename))\n"
      ],
      "metadata": {
        "id": "9M8tmU7aczUr"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Set the paths of the edited and unedited image directories\n",
        "edited_dir = '/content/drive/MyDrive/directory_1/edit_1'\n",
        "unedited_dir = '/content/drive/MyDrive/directory_1/IMAGICA_new'\n",
        "\n",
        "# Set the image dimensions and batch size\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "batch_size = 32\n",
        "\n",
        "# Create the training and validation data generators\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    edited_dir,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    edited_dir,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "# Combine the training and validation data for a larger training set\n",
        "train_ds = train_ds.concatenate(val_ds)\n",
        "\n",
        "# Create the test data generator\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    unedited_dir,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Create the CNN model\n",
        "model = keras.Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_ds, epochs=15)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print('Test accuracy:', accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOvf_4C5iDCr",
        "outputId": "6f38f5d0-495f-4921-ce6d-b95533e10347"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.8343758525459\n"
          ]
        }
      ]
    }
  ]
}