{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHfHHsKA0hoS"
      },
      "outputs": [],
      "source": [
        "# importing the libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Set the path of the directory containing the images\n",
        "dir_path = 'C:\\\\Users\\\\harshith\\\\Downloads\\\\Dataset_Real_vs_Fake_image_BinaryClassifier\\\\images_from_video_big'\n",
        "\n",
        "# Set the paths of the two new directories for edited and unedited images\n",
        "edited_dir_path = os.path.join(dir_path, 'C:\\\\Users\\\\harshith\\\\Downloads\\\\Dataset_Real_vs_Fake_image_BinaryClassifier\\\\images_from_video_big\\\\edited')\n",
        "unedited_dir_path = os.path.join(dir_path, 'C:\\\\Users\\\\harshith\\\\Downloads\\\\Dataset_Real_vs_Fake_image_BinaryClassifier\\\\images_from_video_big\\\\unedited')\n",
        "\n",
        "# Create the new directories if they don't already exist\n",
        "if not os.path.exists(edited_dir_path):\n",
        "    os.makedirs(edited_dir_path)\n",
        "if not os.path.exists(unedited_dir_path):\n",
        "    os.makedirs(unedited_dir_path)\n",
        "\n",
        "# Iterate over all files in the original directory\n",
        "for filename in os.listdir(dir_path):\n",
        "    # Check if the file is a JPG image\n",
        "    if filename.endswith('.jpg'):\n",
        "        # Check the last character of the file name to determine if it is edited or unedited\n",
        "        if filename[-5] == '0':\n",
        "            # Move the file to the unedited directory\n",
        "            shutil.move(os.path.join(dir_path, filename), os.path.join(unedited_dir_path, filename))\n",
        "        elif filename[-5] == '1':\n",
        "            # Move the file to the edited directory\n",
        "            shutil.move(os.path.join(dir_path, filename), os.path.join(edited_dir_path, filename))\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Set the paths of the edited and unedited image directories\n",
        "edited_dir = 'C:\\\\Users\\\\harshith\\\\Downloads\\\\Dataset_Real_vs_Fake_image_BinaryClassifier\\\\images_from_video_big\\\\edited'\n",
        "unedited_dir = 'C:\\\\Users\\\\harshith\\\\Downloads\\\\Dataset_Real_vs_Fake_image_BinaryClassifier\\\\images_from_video_big\\\\unedited'\n",
        "\n",
        "# Set the image dimensions and batch size\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "batch_size = 32\n",
        "\n",
        "# Create the training and validation data generators\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dir_path,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dir_path,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "# Combine the training and validation data for a larger training set\n",
        "train_ds = train_ds.concatenate(val_ds)\n",
        "\n",
        "# Create the test data generator\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dir_path,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Create the CNN model\n",
        "model = keras.Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1. / 255, input_shape=(img_height, img_width, 3)),\n",
        "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_ds, epochs=15)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print('Test accuracy:', accuracy)\n",
        "\n",
        "# output-\n",
        "# \"C:\\Users\\harshith\\Desktop\\py4e\\PYTHON\\sem pycharm\\venv\\Scripts\\python.exe\" \"C:\\Users\\harshith\\Desktop\\py4e\\PYTHON\\sem pycharm\\Alcovex\\Alcovex_task-2.py\"\n",
        "# Found 82621 files belonging to 2 classes.\n",
        "# Using 66097 files for training.\n",
        "# 2023-05-01 09:57:31.692890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
        "# To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
        "# Found 82621 files belonging to 2 classes.\n",
        "# Using 16524 files for validation.\n",
        "# Found 82621 files belonging to 2 classes.\n",
        "# Epoch 1/15\n",
        "# 2583/2583 [==============================] - 824s 318ms/step - loss: 0.5882 - accuracy: 0.6873\n",
        "# Epoch 2/15\n",
        "# 2583/2583 [==============================] - 838s 324ms/step - loss: 0.5066 - accuracy: 0.7434\n",
        "# Epoch 3/15\n",
        "# 2583/2583 [==============================] - 719s 278ms/step - loss: 0.4343 - accuracy: 0.7907\n",
        "# Epoch 4/15\n",
        "# 2583/2583 [==============================] - 759s 294ms/step - loss: 0.3635 - accuracy: 0.8322\n",
        "# Epoch 5/15\n",
        "# 2583/2583 [==============================] - 777s 301ms/step - loss: 0.2894 - accuracy: 0.8717\n",
        "# Epoch 6/15\n",
        "# 2583/2583 [==============================] - 761s 294ms/step - loss: 0.2134 - accuracy: 0.9099\n",
        "# Epoch 7/15\n",
        "# 2583/2583 [==============================] - 762s 295ms/step - loss: 0.1546 - accuracy: 0.9377\n",
        "# Epoch 8/15\n",
        "# 2583/2583 [==============================] - 764s 296ms/step - loss: 0.1181 - accuracy: 0.9530\n",
        "# Epoch 9/15\n",
        "# 2583/2583 [==============================] - 700s 271ms/step - loss: 0.0936 - accuracy: 0.9645\n",
        "# Epoch 10/15\n",
        "# 2583/2583 [==============================] - 591s 229ms/step - loss: 0.0826 - accuracy: 0.9700\n",
        "# Epoch 11/15\n",
        "# 2583/2583 [==============================] - 641s 248ms/step - loss: 0.0705 - accuracy: 0.9748\n",
        "# Epoch 12/15\n",
        "# 2583/2583 [==============================] - 609s 236ms/step - loss: 0.0629 - accuracy: 0.9774\n",
        "# Epoch 13/15\n",
        "# 2583/2583 [==============================] - 593s 229ms/step - loss: 0.0579 - accuracy: 0.9799\n",
        "# Epoch 14/15\n",
        "# 2583/2583 [==============================] - 624s 241ms/step - loss: 0.0544 - accuracy: 0.9812\n",
        "# Epoch 15/15\n",
        "# 2583/2583 [==============================] - 624s 242ms/step - loss: 0.0503 - accuracy: 0.9827\n",
        "# 2582/2582 [==============================] - 206s 80ms/step - loss: 0.1150 - accuracy: 0.9637\n",
        "# Test accuracy: 0.9236533260345459\n",
        "#\n",
        "# Process finished with exit code 0"
      ]
    }
  ]
}